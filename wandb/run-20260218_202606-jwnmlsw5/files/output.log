[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|â–Ž                                                                                                | 12/3362 [11:51<55:09:10, 59.27s/it]Traceback (most recent call last):
{'loss': 0.0, 'grad_norm': 36.6192512512207, 'learning_rate': 0.0, 'num_tokens': 34911.0, 'completions/mean_length': 1023.46875, 'completions/min_length': 1019.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.34375, 'rewards/compute_reward/std': 0.4825586974620819, 'reward': 0.34375, 'reward_std': 0.4397946000099182, 'frac_reward_zero_std': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 47.07632064819336, 'learning_rate': 2.967359050445104e-08, 'num_tokens': 70110.0, 'completions/mean_length': 1023.46875, 'completions/min_length': 1022.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.375, 'rewards/compute_reward/std': 0.49186936020851135, 'reward': 0.375, 'reward_std': 0.3335031569004059, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 10.988263130187988, 'learning_rate': 5.934718100890208e-08, 'num_tokens': 105218.0, 'completions/mean_length': 1023.125, 'completions/min_length': 1020.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.40625, 'rewards/compute_reward/std': 0.49899089336395264, 'reward': 0.40625, 'reward_std': 0.2041158676147461, 'frac_reward_zero_std': 0.5, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': -0.0, 'grad_norm': 7.692189693450928, 'learning_rate': 8.902077151335312e-08, 'num_tokens': 140777.0, 'completions/mean_length': 1023.71875, 'completions/min_length': 1021.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.1875, 'rewards/compute_reward/std': 0.3965577781200409, 'reward': 0.1875, 'reward_std': 0.3104073107242584, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': -0.0, 'grad_norm': 54.262447357177734, 'learning_rate': 1.1869436201780416e-07, 'num_tokens': 176235.0, 'completions/mean_length': 1023.5625, 'completions/min_length': 1020.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.15625, 'rewards/compute_reward/std': 0.3689020276069641, 'reward': 0.15625, 'reward_std': 0.3061639964580536, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': -0.0, 'grad_norm': 13.43851375579834, 'learning_rate': 1.4836795252225522e-07, 'num_tokens': 211742.0, 'completions/mean_length': 1023.34375, 'completions/min_length': 1020.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.3125, 'rewards/compute_reward/std': 0.4709290862083435, 'reward': 0.3125, 'reward_std': 0.38298875093460083, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': -0.0, 'grad_norm': 23.762392044067383, 'learning_rate': 1.7804154302670624e-07, 'num_tokens': 246995.0, 'completions/mean_length': 1023.15625, 'completions/min_length': 1020.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.3125, 'rewards/compute_reward/std': 0.4709290862083435, 'reward': 0.3125, 'reward_std': 0.49022960662841797, 'frac_reward_zero_std': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': -0.0, 'grad_norm': 26.33733367919922, 'learning_rate': 2.0771513353115727e-07, 'num_tokens': 282031.0, 'completions/mean_length': 1023.125, 'completions/min_length': 1017.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.34375, 'rewards/compute_reward/std': 0.4825586974620819, 'reward': 0.34375, 'reward_std': 0.47137710452079773, 'frac_reward_zero_std': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 35.471744537353516, 'learning_rate': 2.3738872403560833e-07, 'num_tokens': 317810.0, 'completions/mean_length': 1023.59375, 'completions/min_length': 1020.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.15625, 'rewards/compute_reward/std': 0.3689020276069641, 'reward': 0.15625, 'reward_std': 0.22201895713806152, 'frac_reward_zero_std': 0.5, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
{'loss': -0.0, 'grad_norm': 151.4425811767578, 'learning_rate': 2.6706231454005935e-07, 'num_tokens': 354005.0, 'completions/mean_length': 1023.59375, 'completions/min_length': 1021.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.21875, 'rewards/compute_reward/std': 0.420013427734375, 'reward': 0.21875, 'reward_std': 0.3377465009689331, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
{'loss': 0.0, 'grad_norm': 26.727031707763672, 'learning_rate': 2.9673590504451043e-07, 'num_tokens': 389018.0, 'completions/mean_length': 1023.15625, 'completions/min_length': 1017.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.34375, 'rewards/compute_reward/std': 0.4825586974620819, 'reward': 0.34375, 'reward_std': 0.3377465009689331, 'frac_reward_zero_std': 0.25, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
{'loss': -0.0, 'grad_norm': 44.24530029296875, 'learning_rate': 3.2640949554896146e-07, 'num_tokens': 424430.0, 'completions/mean_length': 1023.625, 'completions/min_length': 1022.0, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/compute_reward/mean': 0.5, 'rewards/compute_reward/std': 0.5080004930496216, 'reward': 0.5, 'reward_std': 0.4355512857437134, 'frac_reward_zero_std': 0.0, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01}
  File "/root/.vscode-server/memgen/MemGen/main.py", line 115, in <module>
    main()
  File "/root/.vscode-server/memgen/MemGen/main.py", line 109, in main
    runner.train()
  File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 211, in train
    self._train_weaver()
  File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 164, in _train_weaver
    weaver_trainer.train()
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1279, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/root/.vscode-server/memgen/MemGen/memgen/trainer/weaver_grpo_trainer.py", line 291, in _generate_and_score_completions
    final_gen_batch_output = self.generation_manager.run_agent_loop(gen_batch=gen_batch)
  File "/root/.vscode-server/memgen/MemGen/interactions/singleturn_interaction.py", line 109, in run_agent_loop
    gen_output = self.actor_rollout_wg.generate(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/root/.vscode-server/memgen/MemGen/memgen/model/modeling_memgen.py", line 493, in generate
    generated = reasoner.generate(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 2617, in generate
    result = self._sample(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 3601, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 450, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 379, in forward
    hidden_states = decoder_layer(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 231, in forward
    hidden_states, _ = self.self_attn(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 179, in forward
    attn_output = attn_output.reshape(*input_shape, -1).contiguous()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/.vscode-server/memgen/MemGen/main.py", line 115, in <module>
[rank0]:     main()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/main.py", line 109, in main
[rank0]:     runner.train()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 211, in train
[rank0]:     self._train_weaver()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 164, in _train_weaver
[rank0]:     weaver_trainer.train()
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
[rank0]:     inputs = self._prepare_inputs(inputs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
[rank0]:     return func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1279, in _prepare_inputs
[rank0]:     generation_batch = self._generate_and_score_completions(generation_batch)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/trainer/weaver_grpo_trainer.py", line 291, in _generate_and_score_completions
[rank0]:     final_gen_batch_output = self.generation_manager.run_agent_loop(gen_batch=gen_batch)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/interactions/singleturn_interaction.py", line 109, in run_agent_loop
[rank0]:     gen_output = self.actor_rollout_wg.generate(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/model/modeling_memgen.py", line 493, in generate
[rank0]:     generated = reasoner.generate(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 2617, in generate
[rank0]:     result = self._sample(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 3601, in _sample
[rank0]:     outputs = model_forward(**model_inputs, return_dict=True)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 450, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
[rank0]:     outputs = func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 379, in forward
[rank0]:     hidden_states = decoder_layer(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
[rank0]:     return super().__call__(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 231, in forward
[rank0]:     hidden_states, _ = self.self_attn(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 179, in forward
[rank0]:     attn_output = attn_output.reshape(*input_shape, -1).contiguous()
[rank0]: KeyboardInterrupt
