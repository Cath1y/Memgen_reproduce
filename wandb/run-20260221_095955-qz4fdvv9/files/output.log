[34m[1mwandb[0m: Detected [huggingface_hub.inference] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|                                                                                                             | 0/3362 [00:00<?, ?it/s]Traceback (most recent call last):
DEBUG: Weaver activated at step 0 for 4 samples
DEBUG: Weaver activated at step 3 for 1 samples
DEBUG: Weaver activated at step 4 for 1 samples
DEBUG: Weaver activated at step 5 for 4 samples
DEBUG: Weaver activated at step 6 for 1 samples
DEBUG: Weaver activated at step 7 for 1 samples
DEBUG: Weaver activated at step 8 for 4 samples
DEBUG: Weaver activated at step 9 for 3 samples
DEBUG: Weaver activated at step 10 for 2 samples
DEBUG: Weaver activated at step 14 for 1 samples
DEBUG: Weaver activated at step 19 for 3 samples
DEBUG: Weaver activated at step 20 for 1 samples
DEBUG: Weaver activated at step 23 for 1 samples
DEBUG: Weaver activated at step 24 for 2 samples
DEBUG: Weaver activated at step 25 for 2 samples
DEBUG: Weaver activated at step 30 for 1 samples
DEBUG: Weaver activated at step 34 for 1 samples
DEBUG: Weaver activated at step 37 for 2 samples
DEBUG: Weaver activated at step 38 for 2 samples
DEBUG: Weaver activated at step 46 for 2 samples
DEBUG: Weaver activated at step 50 for 1 samples
DEBUG: Weaver activated at step 63 for 1 samples
DEBUG: Weaver activated at step 64 for 1 samples
DEBUG: Weaver activated at step 97 for 1 samples
DEBUG: Weaver activated at step 98 for 1 samples
  File "/root/.vscode-server/memgen/MemGen/main.py", line 115, in <module>
    main()
  File "/root/.vscode-server/memgen/MemGen/main.py", line 109, in main
    runner.train()
  File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 212, in train
    self._train_weaver()
  File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 164, in _train_weaver
    weaver_trainer.train()
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1279, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/root/.vscode-server/memgen/MemGen/memgen/trainer/weaver_grpo_trainer.py", line 291, in _generate_and_score_completions
    final_gen_batch_output = self.generation_manager.run_agent_loop(gen_batch=gen_batch)
  File "/root/.vscode-server/memgen/MemGen/interactions/singleturn_interaction.py", line 109, in run_agent_loop
    gen_output = self.actor_rollout_wg.generate(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/root/.vscode-server/memgen/MemGen/memgen/model/modeling_memgen.py", line 496, in generate
    generated = reasoner.generate(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 2617, in generate
    result = self._sample(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 3601, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 450, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 379, in forward
    hidden_states = decoder_layer(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 231, in forward
    hidden_states, _ = self.self_attn(
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 153, in forward
    value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/peft/tuners/lora/layer.py", line 771, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/.vscode-server/memgen/MemGen/main.py", line 115, in <module>
[rank0]:     main()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/main.py", line 109, in main
[rank0]:     runner.train()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 212, in train
[rank0]:     self._train_weaver()
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/runner.py", line 164, in _train_weaver
[rank0]:     weaver_trainer.train()
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
[rank0]:     inputs = self._prepare_inputs(inputs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
[rank0]:     return func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1279, in _prepare_inputs
[rank0]:     generation_batch = self._generate_and_score_completions(generation_batch)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/trainer/weaver_grpo_trainer.py", line 291, in _generate_and_score_completions
[rank0]:     final_gen_batch_output = self.generation_manager.run_agent_loop(gen_batch=gen_batch)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/interactions/singleturn_interaction.py", line 109, in run_agent_loop
[rank0]:     gen_output = self.actor_rollout_wg.generate(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/root/.vscode-server/memgen/MemGen/memgen/model/modeling_memgen.py", line 496, in generate
[rank0]:     generated = reasoner.generate(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 2617, in generate
[rank0]:     result = self._sample(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/generation/utils.py", line 3601, in _sample
[rank0]:     outputs = model_forward(**model_inputs, return_dict=True)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 450, in forward
[rank0]:     outputs: BaseModelOutputWithPast = self.model(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
[rank0]:     outputs = func(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 379, in forward
[rank0]:     hidden_states = decoder_layer(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/modeling_layers.py", line 93, in __call__
[rank0]:     return super().__call__(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 231, in forward
[rank0]:     hidden_states, _ = self.self_attn(
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 153, in forward
[rank0]:     value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/peft/tuners/lora/layer.py", line 771, in forward
[rank0]:     result = result + lora_B(lora_A(dropout(x))) * scaling
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/memgen/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: KeyboardInterrupt
